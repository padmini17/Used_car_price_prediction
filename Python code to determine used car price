#IMPORTING LIBRARIES REQURIED
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import RandomizedSearchCV

#importing dataset
dataset=pd.read_csv("car data.csv")

dataset.head()

#checking number of rows and columns
dataset.shape

#retriving column names
dataset.columns

#retriving column names
dataset.columns

#prints information about dataset 
dataset.info()

# categorical columns
dataset.select_dtypes(include='object').columns

# numerical columns
dataset.select_dtypes(include=['float64', 'int64']).columns

#returns statistical information about dataset
dataset.describe()

#checking whether the dataset contains any null values
dataset.isnull().values.any()

dataset.head()

#dropping unnecessary fields from dataset
dataset = dataset.drop(columns='Car_Name')

dataset.head()

# adding a column
dataset['Current Year'] = 2023

dataset.head()

#Manipulating dataset 
dataset['Years Old'] = dataset['Current Year'] - dataset['Year']

dataset.head()

#dropping unnecessary fields from dataset
dataset = dataset.drop(columns=['Current Year', 'Year'])

dataset.head()

dataset.select_dtypes(include='object').columns

dataset['Fuel_Type'].unique()

dataset['Seller_Type'].unique()

dataset['Transmission'].unique()

##One Hot Encoding


*   Most Machine Learning algorithms cannot work with categorical data and needs to be ***converted into numerical data***. 
* One hot encoding is a technique used to represent categorical variables as numerical values i.e.**Dummy Variables** in a machine learning model.



# one hot encoding
dataset = pd.get_dummies(data=dataset, drop_first=True)
#drop_first=True helps in reducing the extra column created during dummy variable creation. Hence it reduces the correlations created among dummy variables.

dataset.head()

dataset.shape

dataset_2 = dataset.drop(columns='Selling_Price')

#finding correlation between target variables and predictor variables
dataset_2.corrwith(dataset['Selling_Price']).plot.bar(
    figsize=(16,9), title='Correlated with Selling Price', grid=True
)

corr = dataset.corr()

# heatmap(correlation matrix)
plt.figure(figsize=(16, 9))
sns.heatmap(corr, annot=True)

dataset['Fuel_Type'].unique()

dataset['Seller_Type'].unique()

dataset['Transmission'].unique()

##One Hot Encoding


*   Most Machine Learning algorithms cannot work with categorical data and needs to be ***converted into numerical data***. 
* One hot encoding is a technique used to represent categorical variables as numerical values i.e.**Dummy Variables** in a machine learning model.



# one hot encoding
dataset = pd.get_dummies(data=dataset, drop_first=True)
#drop_first=True helps in reducing the extra column created during dummy variable creation. Hence it reduces the correlations created among dummy variables.

dataset.head()

dataset.shape

dataset_2 = dataset.drop(columns='Selling_Price')

#finding correlation between target variables and predictor variables
dataset_2.corrwith(dataset['Selling_Price']).plot.bar(
    figsize=(16,9), title='Correlated with Selling Price', grid=True
)

corr = dataset.corr()

# heatmap(correlation matrix)
plt.figure(figsize=(16, 9))
sns.heatmap(corr, annot=True)

regressor = RandomForestRegressor(bootstrap=True, criterion='absolute_error',
                      max_depth=50, max_features=1.0,min_samples_leaf=2,
                      min_samples_split=5,n_estimators=700)
regressor.fit(x_train, y_train)

y_pred = regressor.predict(x_test)

r2_score(y_test, y_pred)



---


# Part 5: Predicting a single observation

dataset.head()

single_obs = [[8.50, 400, 0, 5, 1, 0, 0, 1]]

print("Resale Price:",regressor_rf.predict(single_obs))

second_obs = [[10.50, 600, 1, 10, 0, 0, 0, 1]]

print("Resale Price:",regressor_rf.predict(second_obs))

third_obs = [[20.50, 690, 1, 18, 0, 0, 1, 1]]


print("Resale Price:",regressor_rf.predict(third_obs))
